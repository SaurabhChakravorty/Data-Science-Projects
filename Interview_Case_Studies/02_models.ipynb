{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd870e7b",
   "metadata": {},
   "source": [
    "## Model Development and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a11aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from main import get_click_attribution_table, markov_chain, LSTMConversionModel, RandomForestConversionModel # from main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2eff67",
   "metadata": {},
   "source": [
    "The models used and discussed here are following:\n",
    "\n",
    "    1. First and Last touch\n",
    "    2. Markov models with removal effect\n",
    "    3. Random Forest\n",
    "    4. LSTM\n",
    "  \n",
    "`main.py` contains all the modular codes in one place.\n",
    "    \n",
    "> We will use these algorithms to train our modes and understand the motivation behind it.\n",
    "\n",
    "> We will use the test data to calculate the values and see how much do they vary in the results. This affirms the trained model to provide attribution results at any chosen level\n",
    "\n",
    "> The outputs of the models are compared at the next notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attribution = pd.DataFrame(columns = ['channel','model','conversions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e90a6c",
   "metadata": {},
   "source": [
    "### First and last touch attribution\n",
    "\n",
    "> We will do it for test data as it's just last touch(not confirmed for test). For train data we will see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Click\n",
    "first = (\n",
    "    test\n",
    "    .sort_values(by=['user_id', 'timestamp'])\n",
    "    .groupby('user_id')\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('channel').size().reset_index(name='conversions')\n",
    ").sort_values('channel')\n",
    "\n",
    "first['model'] = 'First Click'\n",
    "\n",
    "# Last Click\n",
    "last = (\n",
    "    test\n",
    "    .sort_values(by=['user_id', 'timestamp'])\n",
    "    .groupby('user_id')\n",
    "    .last()\n",
    "    .reset_index()\n",
    "    .groupby('channel').size().reset_index(name='conversions')\n",
    ").sort_values('channel')\n",
    "\n",
    "last['model'] = 'Last Click'\n",
    "test_attribution = pd.concat([test_attribution, first, last], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90045752",
   "metadata": {},
   "source": [
    "### Markov Models\n",
    "\n",
    "The Markov model used here is with removal effect and gives us marketing-based attribution that is both interpretable and actionable. It evaluates each channel’s true influence on conversion by simulating the conversion probability with and without that channel in the journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the results\n",
    "result = markov_chain(train).markov_model()\n",
    "print(result[0].sort_values('channel'))\n",
    "transition_matrix = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ca05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_paths = (\n",
    "    test.sort_values(by=['user_id', 'touchpoint_number'])\n",
    "        .groupby('user_id')['channel']\n",
    "        .apply(list)\n",
    "        .tolist()\n",
    ")\n",
    "\n",
    "\n",
    "channel_contributions = defaultdict(float)\n",
    "\n",
    "for path in user_paths:\n",
    "    prob = markov_chain(test).predict_from_path(path, steps=1, transition_matrix=transition_matrix)\n",
    "\n",
    "    # Remove start/conversion manually\n",
    "    touchpoints = [ch for ch in path if ch not in ('start', 'conversion')]\n",
    "\n",
    "    if len(touchpoints) == 0:\n",
    "        continue\n",
    "\n",
    "    # Distribute probability across the touchpoints\n",
    "    contribution = prob / len(touchpoints)\n",
    "    for ch in touchpoints:\n",
    "        channel_contributions[ch] += contribution\n",
    "\n",
    "# Step 4: Convert to DataFrame\n",
    "markov = pd.DataFrame([\n",
    "    {'channel': ch, 'conversions': val}\n",
    "    for ch, val in channel_contributions.items()\n",
    "]).sort_values('channel').reset_index(drop=True)\n",
    "\n",
    "# Optional: Normalize\n",
    "markov['conversions'] = round(\n",
    "    100 * markov['conversions'] / markov['conversions'].sum(), 2\n",
    ")\n",
    "\n",
    "markov['model']= \"Markov\"\n",
    "test_attribution = pd.concat([test_attribution, markov.sort_values('channel')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893243c",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forest is used as a supervised machine learning model to predict the likelihood of conversion based on touchpoint-level features from a user journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f205b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize and prepare\n",
    "rf_model = RandomForestConversionModel()\n",
    "X_rf, y_rf = rf_model.prepare_data(train[['channel', 'device_type', 'touchpoint_number', 'converted']])\n",
    "\n",
    "# Step 2: Train model and evaluate\n",
    "model, y_prob = rf_model.train(X_rf, y_rf, n_estimators=400)\n",
    "\n",
    "# Step 3: View feature importances\n",
    "print(rf_model.get_feature_importance(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51f416",
   "metadata": {},
   "source": [
    "> Touchpoint number here plays an important role signifying __last touchpoint__ is imperative.\n",
    "\n",
    "> NOTE: We did not use converstion time here as we could not use it for those touchpoints where conversion did not happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Predict conversion probabilities\n",
    "test['conversions'] = RandomForestConversionModel().predict_probabilities(\n",
    "    test[['channel', 'device_type', 'touchpoint_number', 'converted']],\n",
    "    model,\n",
    "    test_data=True\n",
    ")\n",
    "\n",
    "# Step 2: Normalize predictions by user\n",
    "user_sums = test.groupby('user_id')['conversions'].transform('sum')\n",
    "test['conversions'] = test['conversions'] / user_sums\n",
    "test['conversions'] = test['conversions'].fillna(0)\n",
    "\n",
    "# Step 3: Group by channel, sum predictions, and convert to percentages\n",
    "rf = test.groupby('channel')['conversions'].sum().reset_index()\n",
    "\n",
    "\n",
    "# View result\n",
    "rf['model'] = \"Random Forest\"\n",
    "test_attribution = pd.concat([test_attribution, rf.sort_values('channel')], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec12e6",
   "metadata": {},
   "source": [
    "### LSTM \n",
    "\n",
    "LSTM (Long Short-Term Memory) is a deep learning model specifically designed for sequence modeling — making it ideal for analyzing ordered user journey. \n",
    "\n",
    "`NOTE:` We have specifically used bidirectional LSTM to preserve the order of touchpoints and get the probability of conversion at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b766a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "# Create and prepare\n",
    "lstm_model = LSTMConversionModel(context_window=6)\n",
    "X, y, le = lstm_model.prepare_data(train)\n",
    "\n",
    "# Train -> less epochs due to computation\n",
    "model, pred = lstm_model.train(X , y, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window = 6\n",
    "sequences_to_predict = []\n",
    "\n",
    "# Sort test set to preserve order of journeys\n",
    "test = test.sort_values(by=['user_id', 'timestamp'])\n",
    "\n",
    "# Go user by user\n",
    "for user_id, group in test.groupby('user_id'):  \n",
    "    channel_history = []\n",
    "    for _, row in group.iterrows():\n",
    "        channel_history.append(row['channel'])\n",
    "\n",
    "        # Only keep the last `context_window` elements\n",
    "        context_seq = channel_history[-context_window:]\n",
    "\n",
    "        # Store this sequence to predict later\n",
    "        sequences_to_predict.append(context_seq)\n",
    "        \n",
    "\n",
    "# Add prediction column\n",
    "test['conversions'] = LSTMConversionModel(context_window=6).predict_path(model, le, sequences_to_predict)\n",
    "\n",
    "\n",
    "# Step 2: Normalize predictions by user\n",
    "user_sums = test.groupby('user_id')['conversions'].transform('sum')\n",
    "test['conversions'] = test['conversions'] / user_sums\n",
    "test['conversions'] = test['conversions'].fillna(0)\n",
    "\n",
    "# Step 3: Group by channel, sum predictions, and convert to percentages\n",
    "lstm = test.groupby('channel')['conversions'].sum().reset_index()\n",
    "\n",
    "\n",
    "# View result\n",
    "lstm['model'] = \"LSTM\"\n",
    "test_attribution = pd.concat([test_attribution, lstm.sort_values('channel')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0f378",
   "metadata": {},
   "source": [
    "### Tests\n",
    "\n",
    "save the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "test_attribution['percentage'] = test_attribution.groupby('model')['conversions'].transform(lambda x: round(100 * x / x.sum(), 2))\n",
    "test_attribution.reset_index(drop=True).to_csv(\"test_attribution.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
